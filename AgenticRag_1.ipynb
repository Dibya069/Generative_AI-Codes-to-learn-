{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZgc6aSRbzaQ2w4tLpQfwA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dibya069/Generative_AI-Codes-to-learn-/blob/main/AgenticRag_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o65j2lIO9u_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145f0de8-b230-4e3f-9efd-2e5c151f1bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.56-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.9)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.22 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.22-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.54.5)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.43-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain_community) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai)\n",
            "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.26.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Downloading langchain_community-0.3.10-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.56-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.6-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.13.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.22-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.8-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.1.43-py3-none-any.whl (31 kB)\n",
            "Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=77ba3d1d910517438076492ac0d429acdf44b2e1532146b16384e4771d1d9505\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, filetype, durationpy, websockets, uvloop, uvicorn, types-requests, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-proto, langchainhub, coloredlogs, build, pydantic-settings, opentelemetry-exporter-otlp-proto-common, onnxruntime, langgraph-sdk, kubernetes, groq, fastapi, dataclasses-json, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain-openai, langchain-groq, opentelemetry-instrumentation-fastapi, langgraph, langchain, langchain-google-genai, langchain_community, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.6 filetype-1.2.0 groq-0.13.0 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-31.0.0 langchain-0.3.10 langchain-core-0.3.22 langchain-google-genai-2.0.6 langchain-groq-0.2.1 langchain-openai-0.2.11 langchain_community-0.3.10 langchainhub-0.1.21 langgraph-0.2.56 langgraph-checkpoint-2.0.8 langgraph-sdk-0.1.43 marshmallow-3.23.1 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.28.2 opentelemetry-exporter-otlp-proto-grpc-1.28.2 opentelemetry-instrumentation-0.49b2 opentelemetry-instrumentation-asgi-0.49b2 opentelemetry-instrumentation-fastapi-0.49b2 opentelemetry-proto-1.28.2 opentelemetry-util-http-0.49b2 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.1 pydantic-settings-2.6.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.3 tiktoken-0.8.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph  langchain-google-genai langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "GOOGLE_API_KEY =\"AIzaSyAMXLSAGKPT72EOE7vY3fwVOxKUi3NQypA\"\n",
        "GROQ_API_KEY=\"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\"\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "urls = [\n",
        "    \"https://medium.com/@sridevi.gogusetty/rag-vs-graph-rag-llama-3-1-8f2717c554e6\",\n",
        "    \"https://medium.com/@sridevi.gogusetty/retrieval-augmented-generation-rag-gemini-pro-pinecone-1a0a1bfc0534\",\n",
        "    \"https://medium.com/@sridevi.gogusetty/introduction-to-ollama-run-llm-locally-data-privacy-f7e4e58b37a0\",\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_XRsfO-BVJO",
        "outputId": "6013f51c-788a-405c-df81-efee7b608891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "# Add to vectorDB\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=embeddings,\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "WtphuEZpCAqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0UuHB4VDmsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\"What is RAG?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI_383kGCUiz",
        "outputId": "1653865c-2137-49eb-b5e8-ad14103f2094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-0488c522572e>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retriever.get_relevant_documents(\"What is RAG?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'description': 'Retrieval-Augmented Generation (RAG) is a technique that empowers Large Language Models (LLMs) by providing them with relevant information alongside a user query. This “information retrieval” step…', 'language': 'en', 'source': 'https://medium.com/@sridevi.gogusetty/rag-vs-graph-rag-llama-3-1-8f2717c554e6', 'title': 'Rag Vs Graph Rag + Llama 3.1. Retrieval-Augmented Generation (RAG) is… | by Sreedevi Gogusetty | Medium'}, page_content='Rag Vs Graph Rag + Llama 3.1. Retrieval-Augmented Generation (RAG) is… | by Sreedevi Gogusetty | MediumOpen in appSign upSign inWriteSign upSign inRag Vs Graph Rag + Llama 3.1Sreedevi Gogusetty·Follow7 min read·Aug 13, 2024--ListenShareRetrieval-Augmented Generation (RAG) is a technique that empowers Large Language Models (LLMs) by providing them with relevant information alongside a user query. This “information retrieval” step enhances the LLMs ability to generate accurate and comprehensive responses. Here’s how RAG queries workUser Query: The user asks a question or provides a prompt.Retrieval: The system searches for relevant information from a database based on the query’s intent.expand_moreAugmentation: The retrieved information is presented to the LLM alongside the user query.expand_moreGeneration: The LLM leverages both the query and retrieved information to generate a response.expand_moreThere are two main approaches to information retrieval within RAG: Let’s compare Graph RAG vs Vector'),\n",
              " Document(metadata={'description': 'It can be challenging, both in terms of resources and manpower to update them with new information or enhancing context comprehension without retraining or fine-tuning. Retrieval Augmented Generation…', 'language': 'en', 'source': 'https://medium.com/@sridevi.gogusetty/retrieval-augmented-generation-rag-gemini-pro-pinecone-1a0a1bfc0534', 'title': 'Retrieval-Augmented Generation (RAG) + Gemini Pro + Pinecone | by Sreedevi Gogusetty | Medium'}, page_content='“Sydney”.RAG: Searches for the correct answer, finds “Canberra”, and provides it to the user.What is Retrieval-Augmented Generation (RAG)?Retrieval Augmented Generation (RAG) is an advanced artificial intelligence (AI) technique that combines information retrieval with text generation, allowing AI models to retrieve relevant informationRAG stands for Retrieval-Augmented GenerationIt’s an advanced technique used in Large Language Models (LLMs)RAG combines retrieval and generation processes to enhance the capabilities of LLMsIn RAG, the model retrieves relevant information from a knowledge base or external sourcesThis retrieved information is then used in conjunction with the model’s internal knowledge to generate coherent and contextually relevant responsesRAG enables LLMs to produce higher-quality and more context-aware outputs compared to traditional generation methodsEssentially, RAG empowers LLMs to leverage external knowledge for improved performance in various natural language processing tasksRAG architectureLoading custom data -> Ingesting and indexing data in a VectorDB → Querying data using an LLMIts Coding Time !!!!!!!!!!Please install the following in your Google Collab%pip install --upgrade --quiet'),\n",
              " Document(metadata={'description': 'Retrieval-Augmented Generation (RAG) is a technique that empowers Large Language Models (LLMs) by providing them with relevant information alongside a user query. This “information retrieval” step…', 'language': 'en', 'source': 'https://medium.com/@sridevi.gogusetty/rag-vs-graph-rag-llama-3-1-8f2717c554e6', 'title': 'Rag Vs Graph Rag + Llama 3.1. Retrieval-Augmented Generation (RAG) is… | by Sreedevi Gogusetty | Medium'}, page_content='processing a query, Graph RAG explores the knowledge graph, identifying entities and connections relevant to the user’s intent. This approach provides a deeper understanding of the context and relationships within the information.Thematic relevance vs. Context and Relationships:Thematic relevance focuses on how similar topics are. Imagine two documents, one about the French Revolution and another about the American Revolution. Both discuss revolutions, making them thematically relevant to a query about “revolutions.”Context and Relationships delve deeper. Here, we consider not just the topics but also the connections between them. The knowledge graph in Graph RAG might show that the American Revolution was inspired by the French Revolution, providing a richer understanding of the context.Information vs. Entities:Information is a broader term encompassing any kind of knowledge retrieved. In Vector RAG, retrieved information could be entire documents or summaries.Entities are specific objects or concepts within the information. In Graph RAG, the retrieved information focuses on identifying entities (like the French Revolution) and the relationships between them (e.g., historical event with causes).Choosing the Right RAG ApproachThe choice between Vector RAG and Graph RAG depends on your specific needs. Vector'),\n",
              " Document(metadata={'description': 'Retrieval-Augmented Generation (RAG) is a technique that empowers Large Language Models (LLMs) by providing them with relevant information alongside a user query. This “information retrieval” step…', 'language': 'en', 'source': 'https://medium.com/@sridevi.gogusetty/rag-vs-graph-rag-llama-3-1-8f2717c554e6', 'title': 'Rag Vs Graph Rag + Llama 3.1. Retrieval-Augmented Generation (RAG) is… | by Sreedevi Gogusetty | Medium'}, page_content='RAG and delve deeper into each:Rag Vs Graph RagVector RAGImagine a vast library where books are organized based on their thematic connections. Vector RAG employs vector databases. These databases represent information (like documents or entities) as numerical vectors in a high-dimensional space. Documents with similar meanings or topics will have vectors closer together in this space. During retrieval, Vector RAG searches the database for documents with vectors closest to the user query, essentially finding the most thematically relevant information.Example:User Query: “What are the causes of the French Revolution?”Retrieved Information (Vector Search): Documents discussing historical events leading up to the French Revolution, documents on social and economic conditions in 18th century France.Generated Response: The LLM, using the retrieved documents, might explain the various political, social, and economic factors that contributed to the French Revolution.Graph RAGThink of a detailed map where locations and their connections are clearly defined. Graph RAG utilizes knowledge graphs. These are structured databases that represent entities (like people, places, or events) and the relationships between them. During retrieval, Graph RAG traverses the knowledge graph based on the user query, identifying entities and relationships relevant to the')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n"
      ],
      "metadata": {
        "id": "-uklZjguCbpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retrieve_blog_posts\",\n",
        "    \"Search and return information about sridevi gogusetty blog posts on RAG, RAG VS Graph RAG, Ollama.\",\n",
        ")\n",
        "tools = [retriever_tool]"
      ],
      "metadata": {
        "id": "L7Pn7yVSD2eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "HNncr6hAPQs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain.tools.tavily_search import TavilySearchResults\n",
        "# tavily_tool = TavilySearchResults(k=3)\n",
        "search = TavilySearchAPIWrapper()\n",
        "web_search_tool = TavilySearchResults(api_wrapper=search, max_results=5,\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,)"
      ],
      "metadata": {
        "id": "L2w5nWKTPjQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, Sequence, TypedDict\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "class AgentState(TypedDict):\n",
        "    # The add_messages function defines how an update should be processed\n",
        "    # Default is to replace. add_messages says \"append\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]"
      ],
      "metadata": {
        "id": "gUN01Fj4ESvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, Literal, Sequence\n",
        "from typing_extensions import TypedDict"
      ],
      "metadata": {
        "id": "jKhFiI4CEv4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langchain_groq import ChatGroq\n"
      ],
      "metadata": {
        "id": "mgeuYleEFD97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Edges\n",
        "def grade_documents(state) -> Literal[\"generate\", \"web_search\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "    Returns:\n",
        "        str: A decision for whether the documents are relevant or not\n",
        "    \"\"\"\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "    # Data model\n",
        "    class grade(BaseModel):\n",
        "        \"\"\"Binary score for relevance check.\"\"\"\n",
        "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "    # LLM\n",
        "    model =  ChatGroq(temperature=0, model_name=\"gemma2-9b-it\", groq_api_key=GROQ_API_KEY)\n",
        "    # LLM with tool and validation\n",
        "    llm_with_tool = model.with_structured_output(grade)\n",
        "\n",
        "    # Prompt\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "    # Chain\n",
        "    chain = prompt | llm_with_tool\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    question = messages[0].content\n",
        "    docs = last_message.content\n",
        "\n",
        "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
        "    score = scored_result.binary_score\n",
        "    if score == \"yes\":\n",
        "        print(\"---DECISION: DOCS RELEVANT---\")\n",
        "        return \"generate\"\n",
        "    else:\n",
        "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "        print(score)\n",
        "        return \"web_search\"\n"
      ],
      "metadata": {
        "id": "3rHaI_rHMfwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Nodes\n",
        "def web_search_agent(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"messages\"]\n",
        "    query = question[0].content\n",
        "    print(question)\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": query})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web = Document(page_content=web_results)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [web_results]}\n",
        "\n",
        "def retrieve_agent(state):\n",
        "    \"\"\"\n",
        "    Invokes the agent model to generate a response based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "    Returns:\n",
        "        dict: The updated state with the agent response appended to messages\n",
        "    \"\"\"\n",
        "    print(\"---CALL AGENT---\")\n",
        "    messages = state[\"messages\"]\n",
        "    model =  ChatGroq(temperature=0, model_name=\"gemma2-9b-it\", groq_api_key=GROQ_API_KEY)\n",
        "    model = model.bind_tools(tools)\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}\n"
      ],
      "metadata": {
        "id": "53MhpJWyMi5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "    Returns:\n",
        "        dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "    msg = [\n",
        "        HumanMessage(\n",
        "            content=f\"\"\" \\n\n",
        "              Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
        "              Here is the initial question:\n",
        "              \\n ------- \\n\n",
        "              {question}\n",
        "              \\n ------- \\n\n",
        "              Formulate an improved question: \"\"\",\n",
        "        )\n",
        "    ]\n",
        "    llm =  ChatGroq(temperature=0, model_name=\"gemma2-9b-it\", groq_api_key=GROQ_API_KEY)\n",
        "    response = llm.invoke(msg)\n",
        "    return {\"messages\": [response]}\n"
      ],
      "metadata": {
        "id": "EfhWX61SMnOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "    Returns:\n",
        "         dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "    last_message = messages[-1]\n",
        "    docs = last_message.content\n",
        "    # Prompt\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "    # LLM\n",
        "    llm =  ChatGroq(temperature=0, model_name=\"gemma2-9b-it\", groq_api_key=GROQ_API_KEY)\n",
        "    # Post-processing\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "    # Chain\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "    # Run\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "    return {\"messages\": [response]}\n"
      ],
      "metadata": {
        "id": "wwuBbWa6MrMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*\" * 20 + \"Prompt[rlm/rag-prompt]\" + \"*\" * 20)\n",
        "prompt = hub.pull(\"rlm/rag-prompt\").pretty_print()  # Show what the prompt looks like"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYzyL_icMtLd",
        "outputId": "30b224f9-3973-40b2-f45d-98693f4befdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************Prompt[rlm/rag-prompt]********************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
            "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode"
      ],
      "metadata": {
        "id": "gFjSisDWP1Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "# Define the nodes we will cycle between\n",
        "workflow.add_node(\"web_search\", web_search_agent)  # web search\n",
        "workflow.add_node(\"agent\", retrieve_agent)  # agent\n",
        "retrieve = ToolNode([retriever_tool])\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\n",
        "    \"generate\", generate\n",
        ")  # Generating a response after we know the documents are relevant\n",
        "\n",
        "# Call agent node to decide to retrieve or not\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    # Assess agent decision\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Edges taken after the `action` node is called.\n",
        "workflow.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    # Assess agent decision\n",
        "    grade_documents,\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# Compile\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "yqShvve4QAae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "ObRKNuBnQboE",
        "outputId": "ccba7acb-c1ad-4879-a952-88e81ce34cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [\n",
        "        (\"user\", \"how do you play cricket?\"),\n",
        "    ]\n",
        "}\n",
        "for output in graph.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint.pprint(f\"Output from node '{key}':\")\n",
        "        pprint.pprint(\"---\")\n",
        "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint.pprint(\"\\n---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSNGwkMSQIPo",
        "outputId": "2394871b-07a2-4e2c-d436-8c3f8d6954a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CALL AGENT---\n",
            "\"Output from node 'agent':\"\n",
            "'---'\n",
            "{ 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_x8kp', 'function': {'arguments': '{\"query\":\"how to play cricket\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 978, 'total_tokens': 1065, 'completion_time': 0.158181818, 'prompt_time': 0.031286321, 'queue_time': 0.004591463000000004, 'total_time': 0.189468139}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-38da86b9-59ac-46d4-9c1b-ea230e61b2be-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'how to play cricket'}, 'id': 'call_x8kp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 978, 'output_tokens': 87, 'total_tokens': 1065})]}\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "---DECISION: DOCS NOT RELEVANT---\n",
            "no\n",
            "\"Output from node 'retrieve':\"\n",
            "'---'\n",
            "{ 'messages': [ ToolMessage(content='Sreedevi Gogusetty39 Followers·56 FollowingFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\nteaching..RagGraphragLlmRetrieval Augmented GenAgents----FollowWritten by Sreedevi Gogusetty39 Followers·56 FollowingFollowNo responses yetHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n“Sydney”.RAG: Searches for the correct answer, finds “Canberra”, and provides it to the user.What is Retrieval-Augmented Generation (RAG)?Retrieval Augmented Generation (RAG) is an advanced artificial intelligence (AI) technique that combines information retrieval with text generation, allowing AI models to retrieve relevant informationRAG stands for Retrieval-Augmented GenerationIt’s an advanced technique used in Large Language Models (LLMs)RAG combines retrieval and generation processes to enhance the capabilities of LLMsIn RAG, the model retrieves relevant information from a knowledge base or external sourcesThis retrieved information is then used in conjunction with the model’s internal knowledge to generate coherent and contextually relevant responsesRAG enables LLMs to produce higher-quality and more context-aware outputs compared to traditional generation methodsEssentially, RAG empowers LLMs to leverage external knowledge for improved performance in various natural language processing tasksRAG architectureLoading custom data -> Ingesting and indexing data in a VectorDB → Querying data using an LLMIts Coding Time !!!!!!!!!!Please install the following in your Google Collab%pip install --upgrade --quiet\\n\\ngroq_api_key=GROQ_API_KEY)    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)    return chainchain = get_conversational_chain()response = chain(        {\"input_documents\":docs, \"question\":query}        , return_only_outputs=True)print(response[\"output_text\"])You need the below keys to run this code in google collabGoogle API keyGroq API keyYou need to have account in pinecone to get authenticated once authenticated and the code related to creating index is executed you can see the index got created in pinecone vector database with name “langchain-index“ in below screenExample : When i run the Gemini Pro model say query “where she born” see the output in the below screenI hope you enjoyed my article, please free to comment for suggestions.Next article on Graph Rag…. Stay Tuned…Thank you.Happy', name='retrieve_blog_posts', id='293435dc-7197-4bf2-9af6-a0d075bd2fbe', tool_call_id='call_x8kp')]}\n",
            "'\\n---\\n'\n",
            "---WEB SEARCH---\n",
            "[HumanMessage(content='how do you play cricket?', additional_kwargs={}, response_metadata={}, id='cb816483-929b-4165-a0b5-09d810fd3439'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_x8kp', 'function': {'arguments': '{\"query\":\"how to play cricket\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 978, 'total_tokens': 1065, 'completion_time': 0.158181818, 'prompt_time': 0.031286321, 'queue_time': 0.004591463000000004, 'total_time': 0.189468139}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-38da86b9-59ac-46d4-9c1b-ea230e61b2be-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'how to play cricket'}, 'id': 'call_x8kp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 978, 'output_tokens': 87, 'total_tokens': 1065}), ToolMessage(content='Sreedevi Gogusetty39 Followers·56 FollowingFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\nteaching..RagGraphragLlmRetrieval Augmented GenAgents----FollowWritten by Sreedevi Gogusetty39 Followers·56 FollowingFollowNo responses yetHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n“Sydney”.RAG: Searches for the correct answer, finds “Canberra”, and provides it to the user.What is Retrieval-Augmented Generation (RAG)?Retrieval Augmented Generation (RAG) is an advanced artificial intelligence (AI) technique that combines information retrieval with text generation, allowing AI models to retrieve relevant informationRAG stands for Retrieval-Augmented GenerationIt’s an advanced technique used in Large Language Models (LLMs)RAG combines retrieval and generation processes to enhance the capabilities of LLMsIn RAG, the model retrieves relevant information from a knowledge base or external sourcesThis retrieved information is then used in conjunction with the model’s internal knowledge to generate coherent and contextually relevant responsesRAG enables LLMs to produce higher-quality and more context-aware outputs compared to traditional generation methodsEssentially, RAG empowers LLMs to leverage external knowledge for improved performance in various natural language processing tasksRAG architectureLoading custom data -> Ingesting and indexing data in a VectorDB → Querying data using an LLMIts Coding Time !!!!!!!!!!Please install the following in your Google Collab%pip install --upgrade --quiet\\n\\ngroq_api_key=GROQ_API_KEY)    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)    return chainchain = get_conversational_chain()response = chain(        {\"input_documents\":docs, \"question\":query}        , return_only_outputs=True)print(response[\"output_text\"])You need the below keys to run this code in google collabGoogle API keyGroq API keyYou need to have account in pinecone to get authenticated once authenticated and the code related to creating index is executed you can see the index got created in pinecone vector database with name “langchain-index“ in below screenExample : When i run the Gemini Pro model say query “where she born” see the output in the below screenI hope you enjoyed my article, please free to comment for suggestions.Next article on Graph Rag…. Stay Tuned…Thank you.Happy', name='retrieve_blog_posts', id='293435dc-7197-4bf2-9af6-a0d075bd2fbe', tool_call_id='call_x8kp')]\n",
            "\"Output from node 'web_search':\"\n",
            "'---'\n",
            "{ 'messages': [ \"In this comprehensive guide, we've covered the fundamentals \"\n",
            "                'of cricket, playing positions, scoring runs, bowling '\n",
            "                'techniques, strategies, fitness, mental preparation, and the '\n",
            "                'importance of practice. By honing your skills and adopting a '\n",
            "                'professional mindset, you can play cricket like a pro and '\n",
            "                'enjoy the thrill of this incredible sport.\\n'\n",
            "                'How to Play Your First Cricket Game: Simple and Easy Steps. '\n",
            "                'So you are about to play cricket for the first time. Here is '\n",
            "                'a quick guide to help you enjoy your first match. You have '\n",
            "                'already completed the first step by reading this article. Buy '\n",
            "                \"or arrange the necessary equipment that you'll need to play. \"\n",
            "                'A bat and ball is all that is required.\\n'\n",
            "                'Reader Success Stories\\n'\n",
            "                'Diya B.\\n'\n",
            "                'Nov 20, 2023\\n'\n",
            "                'Did this article help you?\\n'\n",
            "                'Diya B.\\n'\n",
            "                'Nov 20, 2023\\n'\n",
            "                'Kare Batycki\\n'\n",
            "                'Jun 28, 2016\\n'\n",
            "                'K. P.\\n'\n",
            "                'Mar 22, 2017\\n'\n",
            "                'Riana Udit\\n'\n",
            "                'Nov 1, 2016\\n'\n",
            "                'Anonymous\\n'\n",
            "                'Feb 9, 2023\\n'\n",
            "                'Quizzes\\n'\n",
            "                'You Might Also Like\\n'\n",
            "                'Featured Articles\\n'\n",
            "                'Trending Articles\\n'\n",
            "                'Featured Articles\\n'\n",
            "                ' Things You Should Know\\n'\n",
            "                'Steps\\n'\n",
            "                'Setting up\\n'\n",
            "                'Understanding Concepts and Rules\\n'\n",
            "                'Playing the Game\\n'\n",
            "                'Expert Q&A\\n'\n",
            "                'Video\\n'\n",
            "                'Tips\\n'\n",
            "                'You Might Also Like\\n'\n",
            "                'References\\n'\n",
            "                'About This Article\\n'\n",
            "                'To play cricket, first gather 2 teams of 11 players. It can '\n",
            "                'also happen if the batsman steps too far forward, misses the '\n",
            "                'ball, and is unable to return to the wicket before the '\n",
            "                'opposing team knocks down the bails. Featured Articles\\n'\n",
            "                'Watch Articles\\n'\n",
            "                'Trending Articles\\n'\n",
            "                'Follow Us\\n'\n",
            "                'wikiHow Tech Help Pro:\\n'\n",
            "                'Level up your tech skills and stay ahead of the curve Lastly, '\n",
            "                'the bowling side can hit the stumps with the ball before the '\n",
            "                'running batsmen make it to the opposite wicket.\\n'\n",
            "                'This quick video will give you some tips on #howto play the '\n",
            "                'game of cricket. Watch to learn all the tricky terminology '\n",
            "                'for this internationally renowned team\\n'\n",
            "                'For more help on how to understand cricket, including how '\n",
            "                'players get out, read on!\\n'\n",
            "                'Reader Success Stories\\n'\n",
            "                'Robert J.\\n'\n",
            "                'Feb 5\\n'\n",
            "                'Did this article help you?\\n'\n",
            "                'About This Article\\n'\n",
            "                'Robert J.\\n'\n",
            "                'Feb 5\\n'\n",
            "                'Chanel Munivai\\n'\n",
            "                'Jun 24, 2018\\n'\n",
            "                'James Rider\\n'\n",
            "                'Aug 16, 2019\\n'\n",
            "                'Kasper van Maasdam\\n'\n",
            "                'Jun 7, 2017\\n'\n",
            "                'Miller Komasinski\\n'\n",
            "                'Jun 25, 2017\\n'\n",
            "                'Quizzes\\n'\n",
            "                ' Steps\\n'\n",
            "                'Understanding the Equipment\\n'\n",
            "                'Understanding the Field\\n'\n",
            "                'Understanding the Players\\n'\n",
            "                'Understanding Gameplay\\n'\n",
            "                'Community Q&A\\n'\n",
            "                'Video\\n'\n",
            "                'Tips\\n'\n",
            "                'You Might Also Like\\n'\n",
            "                'References\\n'\n",
            "                'About This Article\\n'\n",
            "                \"To play cricket, you'll need 2 teams of 11 players who bat in \"\n",
            "                'successive innings and try to score runs. Cricket is a '\n",
            "                'complicated game and can last anywhere from several hours to '\n",
            "                'several days.[1]\\n'\n",
            "                'X\\n'\n",
            "                'Research source\\n'\n",
            "                'It is a very old game that has been around for over 250 '\n",
            "                'years.[2]\\n'\n",
            "                'X\\n'\n",
            "                'Research source\\n'\n",
            "                'Although the general concept of cricket is vaguely similar to '\n",
            "                'baseball, the rules are completely different. You Might Also '\n",
            "                'Like\\n'\n",
            "                'Featured Articles\\n'\n",
            "                'Trending Articles\\n'\n",
            "                'Featured Articles\\n'\n",
            "                'Featured Articles\\n'\n",
            "                'Watch Articles\\n'\n",
            "                'Trending Articles\\n'\n",
            "                'Follow Us\\n'\n",
            "                'Don’t miss out! Log in\\n'\n",
            "                'How to Understand the Basic Rules of Cricket\\n'\n",
            "                'Last Updated: December 30, 2023\\n'\n",
            "                'Approved\\n'\n",
            "                'wikiHow is a “wiki,” similar to Wikipedia, which means that '\n",
            "                'many of our articles are co-written by multiple authors.']}\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Output from node 'generate':\"\n",
            "'---'\n",
            "{ 'messages': [ 'To play cricket, you need two teams of 11 players.  Each team '\n",
            "                'takes turns batting and trying to score runs while the other '\n",
            "                'team bowls and tries to get them out.  Cricket is played on a '\n",
            "                'field with a central pitch and wickets at each end. \\n'\n",
            "                '\\n'\n",
            "                '\\n']}\n",
            "'\\n---\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"messages\": [\n",
        "        (\"user\", \"What is difference between RAG VS GRAPH RAG\"),\n",
        "    ]\n",
        "}\n",
        "for output in graph.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint.pprint(f\"Output from node '{key}':\")\n",
        "        pprint.pprint(\"---\")\n",
        "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint.pprint(\"\\n---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOtsBc0qQhZ8",
        "outputId": "27959d58-2d3c-4893-ad0a-e6219439cdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CALL AGENT---\n",
            "\"Output from node 'agent':\"\n",
            "'---'\n",
            "{ 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_t5p2', 'function': {'arguments': '{\"query\":\"RAG VS Graph RAG\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 980, 'total_tokens': 1067, 'completion_time': 0.158181818, 'prompt_time': 0.031363051, 'queue_time': 0.004161688999999996, 'total_time': 0.189544869}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9ea45d80-12d5-4cec-b6bb-67e08aa11893-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'RAG VS Graph RAG'}, 'id': 'call_t5p2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 980, 'output_tokens': 87, 'total_tokens': 1067})]}\n",
            "'\\n---\\n'\n",
            "---CHECK RELEVANCE---\n",
            "---DECISION: DOCS RELEVANT---\n",
            "\"Output from node 'retrieve':\"\n",
            "'---'\n",
            "{ 'messages': [ ToolMessage(content='processing a query, Graph RAG explores the knowledge graph, identifying entities and connections relevant to the user’s intent. This approach provides a deeper understanding of the context and relationships within the information.Thematic relevance vs. Context and Relationships:Thematic relevance focuses on how similar topics are. Imagine two documents, one about the French Revolution and another about the American Revolution. Both discuss revolutions, making them thematically relevant to a query about “revolutions.”Context and Relationships delve deeper. Here, we consider not just the topics but also the connections between them. The knowledge graph in Graph RAG might show that the American Revolution was inspired by the French Revolution, providing a richer understanding of the context.Information vs. Entities:Information is a broader term encompassing any kind of knowledge retrieved. In Vector RAG, retrieved information could be entire documents or summaries.Entities are specific objects or concepts within the information. In Graph RAG, the retrieved information focuses on identifying entities (like the French Revolution) and the relationships between them (e.g., historical event with causes).Choosing the Right RAG ApproachThe choice between Vector RAG and Graph RAG depends on your specific needs. Vector\\n\\nRag Vs Graph Rag + Llama 3.1. Retrieval-Augmented Generation (RAG) is… | by Sreedevi Gogusetty | MediumOpen in appSign upSign inWriteSign upSign inRag Vs Graph Rag + Llama 3.1Sreedevi Gogusetty·Follow7 min read·Aug 13, 2024--ListenShareRetrieval-Augmented Generation (RAG) is a technique that empowers Large Language Models (LLMs) by providing them with relevant information alongside a user query. This “information retrieval” step enhances the LLMs ability to generate accurate and comprehensive responses. Here’s how RAG queries workUser Query: The user asks a question or provides a prompt.Retrieval: The system searches for relevant information from a database based on the query’s intent.expand_moreAugmentation: The retrieved information is presented to the LLM alongside the user query.expand_moreGeneration: The LLM leverages both the query and retrieved information to generate a response.expand_moreThere are two main approaches to information retrieval within RAG: Let’s compare Graph RAG vs Vector\\n\\nRAG and delve deeper into each:Rag Vs Graph RagVector RAGImagine a vast library where books are organized based on their thematic connections. Vector RAG employs vector databases. These databases represent information (like documents or entities) as numerical vectors in a high-dimensional space. Documents with similar meanings or topics will have vectors closer together in this space. During retrieval, Vector RAG searches the database for documents with vectors closest to the user query, essentially finding the most thematically relevant information.Example:User Query: “What are the causes of the French Revolution?”Retrieved Information (Vector Search): Documents discussing historical events leading up to the French Revolution, documents on social and economic conditions in 18th century France.Generated Response: The LLM, using the retrieved documents, might explain the various political, social, and economic factors that contributed to the French Revolution.Graph RAGThink of a detailed map where locations and their connections are clearly defined. Graph RAG utilizes knowledge graphs. These are structured databases that represent entities (like people, places, or events) and the relationships between them. During retrieval, Graph RAG traverses the knowledge graph based on the user query, identifying entities and relationships relevant to the\\n\\nuser’s intent. This approach provides a deeper understanding of the context and connections within the retrieved information.ExampleUser Query: “Who wrote the Lord of the Rings trilogy?”Retrieved Information (Graph Traversal): Entity for J.R.R. Tolkien with a relationship of “author” to another entity representing the “Lord of the Rings” trilogy.Generated Response: The LLM, using the knowledge graph, would identify J.R.R. Tolkien as the author of the Lord of the Rings trilogy.Graph RAG vs Vector RAGThe key difference between Graph RAG and Vector RAG boils down to how they represent and retrieve information for the LLM.Vector RAG: Think of it as finding similar books in a library. It uses vector databases where information is stored as numerical codes. These codes capture the meaning and themes of the information. During retrieval, Vector RAG searches for information (documents, entities) with codes closest to the user query, essentially finding the most thematically relevant information.Graph RAG: Imagine navigating a detailed map to find connected locations. It uses knowledge graphs which map entities (like people, places, events) and their relationships. When', name='retrieve_blog_posts', id='68f5c07f-1c40-43db-b6e8-12e2304b6f7b', tool_call_id='call_t5p2')]}\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Output from node 'generate':\"\n",
            "'---'\n",
            "{ 'messages': [ 'Vector RAG focuses on finding information with similar themes '\n",
            "                \"to the user's query, using vector databases to represent and \"\n",
            "                'search information.  Graph RAG, on the other hand, uses '\n",
            "                'knowledge graphs to identify entities and the relationships '\n",
            "                'between them, providing a deeper understanding of the '\n",
            "                'context.  The choice between the two depends on whether '\n",
            "                'thematic relevance or contextual relationships are more '\n",
            "                'important for the task. \\n']}\n",
            "'\\n---\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgADSSplQyLx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}